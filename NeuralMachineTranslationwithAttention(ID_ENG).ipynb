{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralMachineTranslationwithAttention(ID-ENG).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxSAeG6cZ3j1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcBbz0VzfzrB",
        "outputId": "a1ed5ebe-adf1-4ce2-cd06-74d7fb79f1e0"
      },
      "source": [
        "!wget http://www.manythings.org/anki/ind-eng.zip\n",
        "!unzip ind-eng.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 08:17:35--  http://www.manythings.org/anki/ind-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 172.67.173.198, 104.24.108.196, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 279153 (273K) [application/zip]\n",
            "Saving to: ‘ind-eng.zip’\n",
            "\n",
            "ind-eng.zip         100%[===================>] 272.61K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-12-21 08:17:35 (2.05 MB/s) - ‘ind-eng.zip’ saved [279153/279153]\n",
            "\n",
            "Archive:  ind-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: ind.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpIAfswBgNc8"
      },
      "source": [
        "path_to_file = \"./ind.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jmfHFhh7Fp"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \",w)\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\",\" \", w)\n",
        "  w = w.strip()\n",
        "\n",
        "  #adding a start and an end token to the sentence, so the model know when to start and when to end\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92YZvFP0jPS4",
        "outputId": "ed92e839-c40d-47e3-eb6f-330c568c2371"
      },
      "source": [
        "en_sentence = u\"May I borrow your book?\"\n",
        "ind_sentence = u\"¿Bolehkah Saya pinjam buku anda?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(ind_sentence).encode('utf-8'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow your book ? <end>\n",
            "b'<start> \\xc2\\xbf bolehkah saya pinjam buku anda ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP1rJxSDlAwS"
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  words_pairs = []\n",
        "\n",
        "  for l in lines[:num_examples]:\n",
        "    word_pairs = []\n",
        "    for w in l.split('\\t'):\n",
        "      if w[:5] == 'CC-BY':\n",
        "        break\n",
        "      word_pairs.append(preprocess_sentence(w))\n",
        "    words_pairs.append(word_pairs)\n",
        "\n",
        "  return zip(*words_pairs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNqHmoflmoIn"
      },
      "source": [
        "en, ind = create_dataset('./ind.txt', None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKl-lUq9m5RB",
        "outputId": "d975a5b8-1933-4e12-dc63-ff9defbe8655"
      },
      "source": [
        "print(en[-1])\n",
        "print(ind[-1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
            "<start> jika seseorang tidak berkesempatan untuk menguasai bahasa yang diinginkannya ketika menginjak dewasa , maka kecil kemungkinan ia akan bisa mencapai tingkatan penutur asli dalam bahasa tersebut . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4vhjKO2o4jA"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8-4pmNDp6Vp"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  target_tensor, target_tokenizer = tokenize(targ_lang)\n",
        "  input_tensor, input_tokenizer = tokenize(inp_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, input_tokenizer, target_tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWqsOZAp7aC"
      },
      "source": [
        "input_tensor, target_tensor, input_tokenizer, target_tokenizer = load_dataset('./ind.txt')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1aD1nWFwVqy"
      },
      "source": [
        "max_length_targ, max_lenght_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9d_ZD4owsbq",
        "outputId": "375798a5-9357-4943-d915-fb88c291e0fe"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5717 5717 1430 1430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD_h48BV00aV"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print(\"%d -----> %s\"%(t, lang.index_word[t]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcJvlTRe1ItO",
        "outputId": "5b739f33-69f8-47d5-8cd4-78efc6cc3f1a"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(input_tokenizer, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(target_tokenizer, target_tensor_train[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 -----> <start>\n",
            "13 -----> itu\n",
            "138 -----> cukup\n",
            "3 -----> .\n",
            "2 -----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 -----> <start>\n",
            "17 -----> that\n",
            "13 -----> s\n",
            "208 -----> enough\n",
            "3 -----> .\n",
            "2 -----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDvnw-U91YDp"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "inp_lang = input_tokenizer\n",
        "targ_lang = target_tokenizer\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6UOEpSc2QZc",
        "outputId": "395c92c0-6a76-444b-989f-703247d75e27"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 29]), TensorShape([64, 38]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWsnEKKQ2hMo"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self,x,hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output,state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naSVJYVJ8bgE"
      },
      "source": [
        "#sample of encoder\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG9tEo5I82E8"
      },
      "source": [
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUmnzQL89Bl4",
        "outputId": "fcf0c8b4-17d7-430b-f9e8-c4a43bfd64ee"
      },
      "source": [
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 29, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Saov4yZ9E9a"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query,1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values)+self.W2(query_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weight = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weight * values\n",
        "    context_vector = tf.reduce_sum(context_vector,axis=1)\n",
        "\n",
        "    return context_vector, attention_weight"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha5Ncbk7Cs7v",
        "outputId": "9b0452ed-a1e7-4fdd-b9b9-0aecc6ddb512"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 29, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U89CX0_SAYXk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences = True, return_state = True, recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weight = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weight"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_XWLeoyCsIx",
        "outputId": "6201710a-2edf-4274-8ca7-610f5eff1fe4"
      },
      "source": [
        "#sample Decoder\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 3583)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAhrDSDACzs9"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real,pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNQr3bSnEY04"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii6g-Q1LEfHS"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    #teacher forcing method\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:,t], predictions)\n",
        "\n",
        "      dec_input = tf.expand_dims(targ[:,t],1)\n",
        "    \n",
        "    batch_loss = (loss/int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6dwY5rhHAt0",
        "outputId": "a18bc93a-6633-4086-ece9-8378bbd5019d"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.7599\n",
            "Epoch 1 Loss 1.1485\n",
            "Time taken for 1 epoch 62.12774419784546 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9209\n",
            "Epoch 2 Loss 0.9414\n",
            "Time taken for 1 epoch 25.415677547454834 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.8390\n",
            "Epoch 3 Loss 0.8272\n",
            "Time taken for 1 epoch 25.270966291427612 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7682\n",
            "Epoch 4 Loss 0.7512\n",
            "Time taken for 1 epoch 25.93952751159668 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.6970\n",
            "Epoch 5 Loss 0.6848\n",
            "Time taken for 1 epoch 25.8406925201416 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.5720\n",
            "Epoch 6 Loss 0.6218\n",
            "Time taken for 1 epoch 26.614359617233276 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.5448\n",
            "Epoch 7 Loss 0.5604\n",
            "Time taken for 1 epoch 26.098541021347046 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.4676\n",
            "Epoch 8 Loss 0.4997\n",
            "Time taken for 1 epoch 26.501379013061523 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4377\n",
            "Epoch 9 Loss 0.4381\n",
            "Time taken for 1 epoch 26.153932332992554 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.3390\n",
            "Epoch 10 Loss 0.3800\n",
            "Time taken for 1 epoch 26.602840423583984 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ40663RPLrp"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_lenght_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_lenght_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCQNB3qTRfmy"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLMxxC8qRi75",
        "outputId": "45726801-3ea7-4a66-edac-204aaae47d3f"
      },
      "source": [
        "!zip -r checkpoint_NMT.zip ./training_checkpoints"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: training_checkpoints/ (stored 0%)\n",
            "  adding: training_checkpoints/ckpt-3.index (deflated 70%)\n",
            "  adding: training_checkpoints/ckpt-4.data-00000-of-00001 (deflated 18%)\n",
            "  adding: training_checkpoints/ckpt-2.data-00000-of-00001 (deflated 18%)\n",
            "  adding: training_checkpoints/checkpoint (deflated 38%)\n",
            "  adding: training_checkpoints/ckpt-4.index (deflated 70%)\n",
            "  adding: training_checkpoints/ckpt-1.data-00000-of-00001 (deflated 18%)\n",
            "  adding: training_checkpoints/ckpt-1.index (deflated 70%)\n",
            "  adding: training_checkpoints/ckpt-3.data-00000-of-00001 (deflated 18%)\n",
            "  adding: training_checkpoints/ckpt-5.index (deflated 70%)\n",
            "  adding: training_checkpoints/ckpt-2.index (deflated 70%)\n",
            "  adding: training_checkpoints/ckpt-5.data-00000-of-00001 (deflated 18%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MomW1t4SRtcu"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmdSRm0MTAlw",
        "outputId": "f9490caf-5afe-41a6-cd65-61f78767ff8d"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdb8fc997f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "h2Usc1N1THzb",
        "outputId": "3946c49a-cccd-4742-a2a0-06adf36db102"
      },
      "source": [
        "translate(u'siapa kamu?')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> siapa kamu ? <end>\n",
            "Predicted translation: what s your name ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OGZYK1cTNvT",
        "outputId": "bca2e7f5-ea67-4c8c-e612-1ce2b8d40833"
      },
      "source": [
        "max_lenght_inp"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rtmEf5qaS-Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}